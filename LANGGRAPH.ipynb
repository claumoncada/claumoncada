{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6976b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "\n",
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]\n",
    "    is_spam: Optional[bool]\n",
    "    draft_response: Optional[str]\n",
    "    messages: List[Dict[str, Any]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ac2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spam(state: EmailState) -> EmailState:\n",
    "    subject = state[\"email\"][\"subject\"]\n",
    "    state[\"is_spam\"] = \"oferta\" in subject.lower()\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a17579b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(EmailState)\n",
    "builder.add_node(\"check_spam\", check_spam)\n",
    "builder.set_entry_point(\"check_spam\")\n",
    "builder.set_finish_point(\"check_spam\")  # o END si hay m√°s nodos\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a714320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email': {'subject': '¬°Gran oferta!', 'body': 'Compra ahora'}, 'is_spam': True, 'messages': []}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"email\": {\"subject\": \"¬°Gran oferta!\", \"body\": \"Compra ahora\"},\n",
    "    \"messages\": []\n",
    "}\n",
    "result = graph.invoke(initial_state)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a96e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmoncada\\AppData\\Local\\Temp\\ipykernel_26892\\4130173885.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Paso 1: Configurar el modelo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Paso 2: Nodo de razonamiento (Chain of Thought)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrazonamiento_node\u001b[39m(state):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cmoncada\\AppData\\Local\\anaconda3\\envs\\crewai\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:224\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cmoncada\\AppData\\Local\\anaconda3\\envs\\crewai\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cmoncada\\AppData\\Local\\anaconda3\\envs\\crewai\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Paso 1: Configurar el modelo\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=\"tu_clave_aqu√≠\")\n",
    "\n",
    "# Paso 2: Nodo de razonamiento (Chain of Thought)\n",
    "def razonamiento_node(state):\n",
    "    mensaje_usuario = state[\"ticket\"]\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Eres un asistente de soporte t√©cnico que razona paso a paso.\"),\n",
    "        HumanMessage(content=f\"Analiza el siguiente ticket y explica paso a paso qu√© tipo de problema es:\\n\\n{mensaje_usuario}\")\n",
    "    ]\n",
    "    razonamiento = llm(prompt).content\n",
    "    return {\"razonamiento\": razonamiento, \"ticket\": mensaje_usuario}\n",
    "\n",
    "# Paso 3: Nodo de clasificaci√≥n\n",
    "def clasificacion_node(state):\n",
    "    razonamiento = state[\"razonamiento\"]\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Eres un clasificador de tickets.\"),\n",
    "        HumanMessage(content=f\"Basado en el siguiente razonamiento, clasifica el ticket como 'problema t√©cnico', 'facturaci√≥n' u 'otro':\\n\\n{razonamiento}\")\n",
    "    ]\n",
    "    categoria = llm(prompt).content\n",
    "    return {\"categoria\": categoria, \"razonamiento\": razonamiento}\n",
    "\n",
    "# Paso 4: Construir el grafo\n",
    "builder = StateGraph()\n",
    "builder.add_node(\"razonamiento\", razonamiento_node)\n",
    "builder.add_node(\"clasificacion\", clasificacion_node)\n",
    "\n",
    "builder.set_entry_point(\"razonamiento\")\n",
    "builder.add_edge(\"razonamiento\", \"clasificacion\")\n",
    "builder.add_edge(\"clasificacion\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Paso 5: Ejecutar el flujo\n",
    "entrada = {\"ticket\": \"No puedo acceder a mi cuenta desde ayer. Me dice que mi contrase√±a es incorrecta.\"}\n",
    "resultado = graph.invoke(entrada)\n",
    "\n",
    "print(\"üß† Razonamiento:\\n\", resultado[\"razonamiento\"])\n",
    "print(\"üìÇ Categor√≠a asignada:\\n\", resultado[\"categoria\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faa012",
   "metadata": {},
   "source": [
    "## Siguiente codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Inicializar modelo\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=\"TU_API_KEY\")\n",
    "\n",
    "# Estado inicial\n",
    "initial_state = {\n",
    "    \"ticket\": \"No puedo acceder a mi cuenta desde ayer. Me dice que mi contrase√±a es incorrecta.\",\n",
    "    \"start_time\": datetime.now(),\n",
    "    \"true_category\": \"problema t√©cnico\",  # Para evaluar accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3daa34",
   "metadata": {},
   "source": [
    " Nodo de Razonamiento Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def razonamiento_node(state):\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Eres un asistente de soporte que razona paso a paso.\"),\n",
    "        HumanMessage(content=f\"Analiza este ticket y explica paso a paso:\\n\\n{state['ticket']}\")\n",
    "    ]\n",
    "    razonamiento = llm(prompt).content\n",
    "    return {**state, \"razonamiento\": razonamiento}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bdecb",
   "metadata": {},
   "source": [
    "Nodo de Clasificaci√≥n de Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificacion_node(state):\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Clasifica el ticket como 'problema t√©cnico', 'facturaci√≥n' u 'otro'.\"),\n",
    "        HumanMessage(content=f\"Basado en este razonamiento:\\n\\n{state['razonamiento']}\")\n",
    "    ]\n",
    "    categoria = llm(prompt).content.strip().lower()\n",
    "    return {**state, \"predicted_category\": categoria}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2df335",
   "metadata": {},
   "source": [
    "Nodo de Escalamiento a Humanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70289def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalamiento_node(state):\n",
    "    # Simulaci√≥n: si el ticket contiene \"no puedo\" o \"error\", escalar\n",
    "    escalar = any(palabra in state[\"ticket\"].lower() for palabra in [\"no puedo\", \"error\", \"bloqueado\"])\n",
    "    return {**state, \"escalado\": escalar}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173249d",
   "metadata": {},
   "source": [
    "Nodo de Registro de M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ff281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_node(state):\n",
    "    end_time = datetime.now()\n",
    "    duracion = (end_time - state[\"start_time\"]).total_seconds()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = 1 if state[\"predicted_category\"] == state[\"true_category\"] else 0\n",
    "\n",
    "    # Tasa de escalamiento (1 si escalado, 0 si no)\n",
    "    escalamiento = 1 if state.get(\"escalado\") else 0\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"tiempo_resolucion\": duracion,\n",
    "        \"accuracy_clasificacion\": accuracy,\n",
    "        \"tasa_escalamiento\": escalamiento\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa285c79",
   "metadata": {},
   "source": [
    "Nodo de Generaci√≥n de Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta_node(state):\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Genera una respuesta clara y √∫til para el cliente.\"),\n",
    "        HumanMessage(content=f\"Ticket: {state['ticket']}\\nCategor√≠a: {state['predicted_category']}\")\n",
    "    ]\n",
    "    respuesta = llm(prompt).content\n",
    "    return {**state, \"respuesta\": respuesta}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2048fb6",
   "metadata": {},
   "source": [
    "Construcci√≥n del Grafo LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph()\n",
    "builder.add_node(\"razonamiento\", razonamiento_node)\n",
    "builder.add_node(\"clasificacion\", clasificacion_node)\n",
    "builder.add_node(\"escalamiento\", escalamiento_node)\n",
    "builder.add_node(\"metricas\", metricas_node)\n",
    "builder.add_node(\"respuesta\", respuesta_node)\n",
    "\n",
    "builder.set_entry_point(\"razonamiento\")\n",
    "builder.add_edge(\"razonamiento\", \"clasificacion\")\n",
    "builder.add_edge(\"clasificacion\", \"escalamiento\")\n",
    "builder.add_edge(\"escalamiento\", \"metricas\")\n",
    "builder.add_edge(\"metricas\", \"respuesta\")\n",
    "builder.add_edge(\"respuesta\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "resultado = graph.invoke(initial_state)\n",
    "\n",
    "# Mostrar resultados\n",
    "for clave in [\"razonamiento\", \"predicted_category\", \"escalado\", \"tiempo_resolucion\", \"accuracy_clasificacion\", \"tasa_escalamiento\", \"respuesta\"]:\n",
    "    print(f\"{clave.upper()}:\\n{resultado[clave]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
