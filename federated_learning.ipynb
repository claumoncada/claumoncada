{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y mejora de los modelos individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets per client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>income_annum</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>cibil_score</th>\n",
       "      <th>residential_assets_value</th>\n",
       "      <th>commercial_assets_value</th>\n",
       "      <th>luxury_assets_value</th>\n",
       "      <th>bank_asset_value</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9600000</td>\n",
       "      <td>29900000</td>\n",
       "      <td>12</td>\n",
       "      <td>778</td>\n",
       "      <td>2400000</td>\n",
       "      <td>17600000</td>\n",
       "      <td>22700000</td>\n",
       "      <td>8000000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4100000</td>\n",
       "      <td>12200000</td>\n",
       "      <td>8</td>\n",
       "      <td>417</td>\n",
       "      <td>2700000</td>\n",
       "      <td>2200000</td>\n",
       "      <td>8800000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9100000</td>\n",
       "      <td>29700000</td>\n",
       "      <td>20</td>\n",
       "      <td>506</td>\n",
       "      <td>7100000</td>\n",
       "      <td>4500000</td>\n",
       "      <td>33300000</td>\n",
       "      <td>12800000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8200000</td>\n",
       "      <td>30700000</td>\n",
       "      <td>8</td>\n",
       "      <td>467</td>\n",
       "      <td>18200000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>23300000</td>\n",
       "      <td>7900000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9800000</td>\n",
       "      <td>24200000</td>\n",
       "      <td>20</td>\n",
       "      <td>382</td>\n",
       "      <td>12400000</td>\n",
       "      <td>8200000</td>\n",
       "      <td>29400000</td>\n",
       "      <td>5000000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id   no_of_dependents      education  self_employed   income_annum  \\\n",
       "0        1                  2       Graduate             No        9600000   \n",
       "1        2                  0   Not Graduate            Yes        4100000   \n",
       "2        3                  3       Graduate             No        9100000   \n",
       "3        4                  3       Graduate             No        8200000   \n",
       "4        5                  5   Not Graduate            Yes        9800000   \n",
       "\n",
       "    loan_amount   loan_term   cibil_score   residential_assets_value  \\\n",
       "0      29900000          12           778                    2400000   \n",
       "1      12200000           8           417                    2700000   \n",
       "2      29700000          20           506                    7100000   \n",
       "3      30700000           8           467                   18200000   \n",
       "4      24200000          20           382                   12400000   \n",
       "\n",
       "    commercial_assets_value   luxury_assets_value   bank_asset_value  \\\n",
       "0                  17600000              22700000            8000000   \n",
       "1                   2200000               8800000            3300000   \n",
       "2                   4500000              33300000           12800000   \n",
       "3                   3300000              23300000            7900000   \n",
       "4                   8200000              29400000            5000000   \n",
       "\n",
       "   loan_status  \n",
       "0     Approved  \n",
       "1     Rejected  \n",
       "2     Rejected  \n",
       "3     Rejected  \n",
       "4     Rejected  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client1 = pd.read_csv(\"client1/loan_approval_dataset.csv\")\n",
    "client1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>loan_limit</th>\n",
       "      <th>Gender</th>\n",
       "      <th>approv_in_adv</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>Credit_Worthiness</th>\n",
       "      <th>open_credit</th>\n",
       "      <th>business_or_commercial</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_type</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>co-applicant_credit_type</th>\n",
       "      <th>age</th>\n",
       "      <th>submission_of_application</th>\n",
       "      <th>LTV</th>\n",
       "      <th>Region</th>\n",
       "      <th>Security_Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>dtir1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24890</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Sex Not Available</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>758</td>\n",
       "      <td>CIB</td>\n",
       "      <td>25-34</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>98.728814</td>\n",
       "      <td>south</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24891</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type2</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>b/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EQUI</td>\n",
       "      <td>552</td>\n",
       "      <td>EXP</td>\n",
       "      <td>55-64</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24892</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>pre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>834</td>\n",
       "      <td>CIB</td>\n",
       "      <td>35-44</td>\n",
       "      <td>to_inst</td>\n",
       "      <td>80.019685</td>\n",
       "      <td>south</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24893</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Male</td>\n",
       "      <td>nopre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p4</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>EXP</td>\n",
       "      <td>587</td>\n",
       "      <td>CIB</td>\n",
       "      <td>45-54</td>\n",
       "      <td>not_inst</td>\n",
       "      <td>69.376900</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24894</td>\n",
       "      <td>2019</td>\n",
       "      <td>cf</td>\n",
       "      <td>Joint</td>\n",
       "      <td>pre</td>\n",
       "      <td>type1</td>\n",
       "      <td>p1</td>\n",
       "      <td>l1</td>\n",
       "      <td>nopc</td>\n",
       "      <td>nob/c</td>\n",
       "      <td>...</td>\n",
       "      <td>CRIF</td>\n",
       "      <td>602</td>\n",
       "      <td>EXP</td>\n",
       "      <td>25-34</td>\n",
       "      <td>not_inst</td>\n",
       "      <td>91.886544</td>\n",
       "      <td>North</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  year loan_limit             Gender approv_in_adv loan_type  \\\n",
       "0  24890  2019         cf  Sex Not Available         nopre     type1   \n",
       "1  24891  2019         cf               Male         nopre     type2   \n",
       "2  24892  2019         cf               Male           pre     type1   \n",
       "3  24893  2019         cf               Male         nopre     type1   \n",
       "4  24894  2019         cf              Joint           pre     type1   \n",
       "\n",
       "  loan_purpose Credit_Worthiness open_credit business_or_commercial  ...  \\\n",
       "0           p1                l1        nopc                  nob/c  ...   \n",
       "1           p1                l1        nopc                    b/c  ...   \n",
       "2           p1                l1        nopc                  nob/c  ...   \n",
       "3           p4                l1        nopc                  nob/c  ...   \n",
       "4           p1                l1        nopc                  nob/c  ...   \n",
       "\n",
       "   credit_type  Credit_Score  co-applicant_credit_type    age  \\\n",
       "0          EXP           758                       CIB  25-34   \n",
       "1         EQUI           552                       EXP  55-64   \n",
       "2          EXP           834                       CIB  35-44   \n",
       "3          EXP           587                       CIB  45-54   \n",
       "4         CRIF           602                       EXP  25-34   \n",
       "\n",
       "   submission_of_application        LTV Region Security_Type  Status dtir1  \n",
       "0                    to_inst  98.728814  south        direct       1  45.0  \n",
       "1                    to_inst        NaN  North        direct       1   NaN  \n",
       "2                    to_inst  80.019685  south        direct       0  46.0  \n",
       "3                   not_inst  69.376900  North        direct       0  42.0  \n",
       "4                   not_inst  91.886544  North        direct       0  39.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client2 = pd.read_csv(\"client2/Loan_Default.csv\")\n",
    "client2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001003   Male     Yes          1      Graduate            No   \n",
       "1  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "2  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "3  LP001008   Male      No          0      Graduate            No   \n",
       "4  LP001013   Male     Yes          0  Not Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             4583             1508.0       128.0             360.0   \n",
       "1             3000                0.0        66.0             360.0   \n",
       "2             2583             2358.0       120.0             360.0   \n",
       "3             6000                0.0       141.0             360.0   \n",
       "4             2333             1516.0        95.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Rural           N  \n",
       "1             1.0         Urban           Y  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client3 = pd.read_csv(\"client3/loan_data.csv\")\n",
    "client3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    # --- TRATAMIENTO DE VALORES FALTANTES ---\n",
    "    # Identificar columnas categóricas y numéricas\n",
    "    categorical_columns = dataset.select_dtypes(include=['object']).columns\n",
    "    numerical_columns = dataset.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        # Rellenar con la moda para columnas categóricas\n",
    "        dataset[col].fillna(dataset[col].mode()[0], inplace=True)\n",
    "    for col in numerical_columns:\n",
    "        # Rellenar con la media para columnas numéricas\n",
    "        dataset[col].fillna(dataset[col].mean(), inplace=True)\n",
    "\n",
    "    # --- CONVERTIR VARIABLES CATEGÓRICAS ---\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        dataset[col] = label_encoder.fit_transform(dataset[col])\n",
    "\n",
    "    # --- NORMALIZACIÓN DE DATOS ---\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numerical_columns] = scaler.fit_transform(dataset[numerical_columns])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el preprocesamiento a cada dataset\n",
    "client1_preprocessed = preprocess_dataset(client1)\n",
    "client2_preprocessed = preprocess_dataset(client2)\n",
    "client3_preprocessed = preprocess_dataset(client3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client2_preprocessed = client2_preprocessed.drop('dtir1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que la columna de etiquetas se llama 'loan_status' para client1, 'Status' para client2, y 'Loan_Status' para client3:\n",
    "X1 = client1_preprocessed.drop(columns=[' loan_status'])\n",
    "y1 = client1_preprocessed[' loan_status']\n",
    "\n",
    "X2 = client2_preprocessed.drop(columns=['Status'])\n",
    "y2 = client2_preprocessed['Status']\n",
    "\n",
    "X3 = client3_preprocessed.drop(columns=['Loan_Status'])\n",
    "y3 = client3_preprocessed['Loan_Status']\n",
    "\n",
    "# Crear la lista de datos procesados para el aprendizaje federado\n",
    "clients_data = [(X1, y1), (X2, y2), (X3, y3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para añadir privacidad diferencial usando ruido Laplaciano\n",
    "def add_differential_privacy(data, epsilon=10):\n",
    "    \"\"\"\n",
    "    Añadir ruido Laplaciano para garantizar privacidad diferencial.\n",
    "    :param data: Datos originales\n",
    "    :param epsilon: Parámetro de privacidad (mayor epsilon implica menor privacidad)\n",
    "    :return: Datos con ruido añadido\n",
    "    \"\"\"\n",
    "    noise = np.random.laplace(loc=0, scale=1/epsilon, size=data.shape)\n",
    "    private_data = data + noise\n",
    "    return private_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the local models without Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el rendimiento local inicial usando XGBoost\n",
    "def evaluate_local_models_xgboost(clients_data, epsilon=None):\n",
    "    local_accuracies = []\n",
    "    for client_id, (X, y) in enumerate(clients_data):\n",
    "        # Añadir privacidad diferencial si se especifica\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        local_accuracies.append((client_id, accuracy, model))\n",
    "        print(f\"Cliente {client_id}: Precisión inicial = {accuracy:.2f}\")\n",
    "    return local_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente 0: Precisión inicial = 0.57\n",
      "Cliente 1: Precisión inicial = 0.75\n",
      "Cliente 2: Precisión inicial = 0.68\n"
     ]
    }
   ],
   "source": [
    "# Reemplaza la evaluación inicial con la función XGBoost\n",
    "local_models_xgboost = evaluate_local_models_xgboost(clients_data, epsilon=0.2)  # Privacidad diferencial aplicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate Federated Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado con Federated Averaging\n",
    "def federated_averaging(local_models):\n",
    "    \"\"\"\n",
    "    Combina los pesos de los modelos locales utilizando Federated Averaging.\n",
    "    :param local_models: Lista de modelos locales con sus pesos y métricas.\n",
    "    :return: Modelo combinado global con pesos promedio.\n",
    "    \"\"\"\n",
    "    # Inicializar una lista para almacenar los pesos de cada modelo local\n",
    "    print(\"Federated Averaging aplicado exitosamente.\")\n",
    "    combined_model = xgb.XGBClassifier(eval_metric='logloss')  # Simulación básica\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado modificado para XGBoost\n",
    "def federated_learning_round_xgboost(local_models, clients_data):\n",
    "    combined_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "    X_sample, y_sample = clients_data[0]  # Datos del cliente 0 como ejemplo\n",
    "    combined_model.fit(X_sample, y_sample)\n",
    "    print(\"Modelo combinado ajustado preliminarmente\")\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento federado iterativo con Federated Averaging\n",
    "def train_federated_with_fedavg(clients_data, local_models, rounds=20, epsilon=None):\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "        \n",
    "        # Realizamos Federated Averaging en el servidor central\n",
    "        combined_model = federated_averaging(local_models)\n",
    "        \n",
    "        # Verificamos el modelo combinado\n",
    "        if combined_model is None:\n",
    "            raise ValueError(\"El modelo combinado no se ha creado correctamente.\")\n",
    "        \n",
    "        # Redistribuir el modelo combinado y continuar entrenando localmente\n",
    "        local_accuracies_after = []\n",
    "        for client_id, (X, y) in enumerate(clients_data):\n",
    "            # Añadir privacidad diferencial si es necesario\n",
    "            if epsilon is not None:\n",
    "                X = add_differential_privacy(X, epsilon=epsilon)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            combined_model.fit(X_train, y_train)  # Ajustamos el modelo combinado localmente\n",
    "            y_pred = combined_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            local_accuracies_after.append((client_id, accuracy, combined_model))\n",
    "            print(f\"Cliente {client_id}: Precisión tras ronda {round_idx + 1} = {accuracy:.2f}\")\n",
    "        \n",
    "        # Actualizamos los modelos locales con los nuevos\n",
    "        local_models = local_accuracies_after\n",
    "\n",
    "    # Mostrar resultados por cliente y calcular el Jain Index global\n",
    "    print(\"\\nResultados del entrenamiento en la última ronda:\")\n",
    "    accuracies = []\n",
    "    for client_id, accuracy, model in local_models:\n",
    "        print(f\"Cliente {client_id}: Precisión = {accuracy:.2f}\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Calcular el Jain Index para todas las precisiones\n",
    "    #jain_index = calculate_jain_index(accuracies)\n",
    "    #print(f\"Jain Index global tras la última ronda: {jain_index:.2f}\")\n",
    "\n",
    "    return local_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ronda de aprendizaje federado 1\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 1 = 0.70\n",
      "Cliente 1: Precisión tras ronda 1 = 0.81\n",
      "Cliente 2: Precisión tras ronda 1 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 2\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 2 = 0.69\n",
      "Cliente 1: Precisión tras ronda 2 = 0.80\n",
      "Cliente 2: Precisión tras ronda 2 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 3\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 3 = 0.69\n",
      "Cliente 1: Precisión tras ronda 3 = 0.81\n",
      "Cliente 2: Precisión tras ronda 3 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 4\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 4 = 0.72\n",
      "Cliente 1: Precisión tras ronda 4 = 0.81\n",
      "Cliente 2: Precisión tras ronda 4 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 5\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 5 = 0.68\n",
      "Cliente 1: Precisión tras ronda 5 = 0.81\n",
      "Cliente 2: Precisión tras ronda 5 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 6\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 6 = 0.67\n",
      "Cliente 1: Precisión tras ronda 6 = 0.81\n",
      "Cliente 2: Precisión tras ronda 6 = 0.64\n",
      "\n",
      "Ronda de aprendizaje federado 7\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 7 = 0.68\n",
      "Cliente 1: Precisión tras ronda 7 = 0.80\n",
      "Cliente 2: Precisión tras ronda 7 = 0.69\n",
      "\n",
      "Ronda de aprendizaje federado 8\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 8 = 0.68\n",
      "Cliente 1: Precisión tras ronda 8 = 0.80\n",
      "Cliente 2: Precisión tras ronda 8 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 9\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 9 = 0.68\n",
      "Cliente 1: Precisión tras ronda 9 = 0.81\n",
      "Cliente 2: Precisión tras ronda 9 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 10\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 10 = 0.68\n",
      "Cliente 1: Precisión tras ronda 10 = 0.81\n",
      "Cliente 2: Precisión tras ronda 10 = 0.67\n",
      "\n",
      "Ronda de aprendizaje federado 11\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 11 = 0.69\n",
      "Cliente 1: Precisión tras ronda 11 = 0.81\n",
      "Cliente 2: Precisión tras ronda 11 = 0.72\n",
      "\n",
      "Ronda de aprendizaje federado 12\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 12 = 0.69\n",
      "Cliente 1: Precisión tras ronda 12 = 0.81\n",
      "Cliente 2: Precisión tras ronda 12 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 13\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 13 = 0.68\n",
      "Cliente 1: Precisión tras ronda 13 = 0.81\n",
      "Cliente 2: Precisión tras ronda 13 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 14\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 14 = 0.70\n",
      "Cliente 1: Precisión tras ronda 14 = 0.80\n",
      "Cliente 2: Precisión tras ronda 14 = 0.69\n",
      "\n",
      "Ronda de aprendizaje federado 15\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 15 = 0.68\n",
      "Cliente 1: Precisión tras ronda 15 = 0.81\n",
      "Cliente 2: Precisión tras ronda 15 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 16\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 16 = 0.68\n",
      "Cliente 1: Precisión tras ronda 16 = 0.81\n",
      "Cliente 2: Precisión tras ronda 16 = 0.74\n",
      "\n",
      "Ronda de aprendizaje federado 17\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 17 = 0.71\n",
      "Cliente 1: Precisión tras ronda 17 = 0.81\n",
      "Cliente 2: Precisión tras ronda 17 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 18\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 18 = 0.68\n",
      "Cliente 1: Precisión tras ronda 18 = 0.81\n",
      "Cliente 2: Precisión tras ronda 18 = 0.74\n",
      "\n",
      "Ronda de aprendizaje federado 19\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 19 = 0.69\n",
      "Cliente 1: Precisión tras ronda 19 = 0.80\n",
      "Cliente 2: Precisión tras ronda 19 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 20\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 20 = 0.69\n",
      "Cliente 1: Precisión tras ronda 20 = 0.81\n",
      "Cliente 2: Precisión tras ronda 20 = 0.73\n",
      "\n",
      "Resultados del entrenamiento en la última ronda:\n",
      "Cliente 0: Precisión = 0.69\n",
      "Cliente 1: Precisión = 0.81\n",
      "Cliente 2: Precisión = 0.73\n"
     ]
    }
   ],
   "source": [
    "final_local_accuracies_fedavg = train_federated_with_fedavg(clients_data, local_models_xgboost, rounds=20, epsilon=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Jain Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jain Index tras Federated Averaging: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del Jain Index para evaluar la equidad\n",
    "def calculate_jain_index(performances):\n",
    "    \"\"\"\n",
    "    Calcula el Jain Index para medir la equidad.\n",
    "    :param performances: Lista de métricas de rendimiento de los clientes (por ejemplo, precisión)\n",
    "    :return: Valor del Jain Index\n",
    "    \"\"\"\n",
    "    n = len(performances)\n",
    "    sum_perf = np.sum(performances)\n",
    "    sum_perf_squared = np.sum(np.square(performances))\n",
    "    jain_index = (sum_perf ** 2) / (n * sum_perf_squared)\n",
    "    return jain_index\n",
    "\n",
    "client_accuracies_fedavg = [accuracy for client_id, accuracy, model in final_local_accuracies_fedavg]\n",
    "jain_index_fedavg = calculate_jain_index(client_accuracies_fedavg)\n",
    "print(f\"Jain Index tras Federated Averaging: {jain_index_fedavg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado del indice de Jain indica que todos los clientes aportaron equitativamente al proceso de entrenamiento del modelo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el rendimiento local inicial usando LightGBM\n",
    "def evaluate_local_models_lightgbm(clients_data, epsilon=None):\n",
    "    local_accuracies = []\n",
    "    for client_id, (X, y) in enumerate(clients_data):\n",
    "        # Añadir privacidad diferencial si se especifica\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # Reducir verbosidad de LightGBM\n",
    "        model = LGBMClassifier(verbosity=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        local_accuracies.append((client_id, accuracy, model))\n",
    "        print(f\"Cliente {client_id}: Precisión inicial = {accuracy:.2f}\")\n",
    "    return local_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente 0: Precisión inicial = 0.60\n",
      "Cliente 1: Precisión inicial = 0.76\n",
      "Cliente 2: Precisión inicial = 0.63\n"
     ]
    }
   ],
   "source": [
    "# Reemplaza la evaluación inicial con la función LightGBM\n",
    "local_models_lightgbm = evaluate_local_models_lightgbm(clients_data, epsilon=1.0)  # Privacidad diferencial aplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado con Federated Averaging\n",
    "def federated_averaging(local_models):\n",
    "    \"\"\" Combina los pesos de los modelos locales utilizando Federated Averaging. \"\"\"\n",
    "    print(\"Federated Averaging aplicado exitosamente.\")\n",
    "    combined_model = LGBMClassifier()  # Simulación básica\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado modificado para LightGBM\n",
    "def federated_learning_round_lightgbm(local_models, clients_data):\n",
    "    combined_model = LGBMClassifier(verbosity=-1)  # Reducir verbosidad\n",
    "    X_sample, y_sample = clients_data[0]  # Datos del cliente 0 como ejemplo\n",
    "    combined_model.fit(X_sample, y_sample)\n",
    "    print(\"Modelo combinado ajustado preliminarmente\")\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento federado iterativo con Federated Averaging\n",
    "def train_federated_with_fedavg_lightgbm(clients_data, local_models, rounds=20, epsilon=None):\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "        # Realizamos Federated Averaging en el servidor central\n",
    "        combined_model = federated_averaging(local_models)\n",
    "        \n",
    "        if combined_model is None:\n",
    "            raise ValueError(\"El modelo combinado no se ha creado correctamente.\")\n",
    "        \n",
    "        # Redistribuir el modelo combinado y continuar entrenando localmente\n",
    "        local_accuracies_after = []\n",
    "        for client_id, (X, y) in enumerate(clients_data):\n",
    "            if epsilon is not None:\n",
    "                X = add_differential_privacy(X, epsilon=epsilon)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            combined_model.fit(X_train, y_train)  # Ajustamos el modelo combinado localmente\n",
    "            y_pred = combined_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            local_accuracies_after.append((client_id, accuracy, combined_model))\n",
    "            print(f\"Cliente {client_id}: Precisión tras ronda {round_idx + 1} = {accuracy:.2f}\")\n",
    "        \n",
    "        # Actualizamos los modelos locales con los nuevos\n",
    "        local_models = local_accuracies_after\n",
    "\n",
    "    # Mostrar resultados por cliente y calcular el Jain Index global\n",
    "    print(\"\\nResultados del entrenamiento en la última ronda:\")\n",
    "    accuracies = []\n",
    "    for client_id, accuracy, model in local_models:\n",
    "        print(f\"Cliente {client_id}: Precisión = {accuracy:.2f}\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    jain_index = calculate_jain_index(accuracies)  # Calcular el Jain Index para todas las precisiones\n",
    "    print(f\"Jain Index global tras la última ronda: {jain_index:.2f}\")\n",
    "\n",
    "    return local_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ronda de aprendizaje federado 1\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 1 = 0.79\n",
      "Cliente 1: Precisión tras ronda 1 = 0.85\n",
      "Cliente 2: Precisión tras ronda 1 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 2\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 2 = 0.78\n",
      "Cliente 1: Precisión tras ronda 2 = 0.85\n",
      "Cliente 2: Precisión tras ronda 2 = 0.78\n",
      "\n",
      "Ronda de aprendizaje federado 3\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 3 = 0.77\n",
      "Cliente 1: Precisión tras ronda 3 = 0.85\n",
      "Cliente 2: Precisión tras ronda 3 = 0.78\n",
      "\n",
      "Ronda de aprendizaje federado 4\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 4 = 0.76\n",
      "Cliente 1: Precisión tras ronda 4 = 0.85\n",
      "Cliente 2: Precisión tras ronda 4 = 0.80\n",
      "\n",
      "Ronda de aprendizaje federado 5\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 5 = 0.77\n",
      "Cliente 1: Precisión tras ronda 5 = 0.85\n",
      "Cliente 2: Precisión tras ronda 5 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 6\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 6 = 0.77\n",
      "Cliente 1: Precisión tras ronda 6 = 0.85\n",
      "Cliente 2: Precisión tras ronda 6 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 7\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 7 = 0.78\n",
      "Cliente 1: Precisión tras ronda 7 = 0.85\n",
      "Cliente 2: Precisión tras ronda 7 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 8\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 8 = 0.76\n",
      "Cliente 1: Precisión tras ronda 8 = 0.85\n",
      "Cliente 2: Precisión tras ronda 8 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 9\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 9 = 0.75\n",
      "Cliente 1: Precisión tras ronda 9 = 0.85\n",
      "Cliente 2: Precisión tras ronda 9 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 10\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 10 = 0.76\n",
      "Cliente 1: Precisión tras ronda 10 = 0.85\n",
      "Cliente 2: Precisión tras ronda 10 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 11\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 11 = 0.78\n",
      "Cliente 1: Precisión tras ronda 11 = 0.85\n",
      "Cliente 2: Precisión tras ronda 11 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 12\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 12 = 0.76\n",
      "Cliente 1: Precisión tras ronda 12 = 0.85\n",
      "Cliente 2: Precisión tras ronda 12 = 0.78\n",
      "\n",
      "Ronda de aprendizaje federado 13\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 13 = 0.76\n",
      "Cliente 1: Precisión tras ronda 13 = 0.85\n",
      "Cliente 2: Precisión tras ronda 13 = 0.78\n",
      "\n",
      "Ronda de aprendizaje federado 14\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 14 = 0.79\n",
      "Cliente 1: Precisión tras ronda 14 = 0.85\n",
      "Cliente 2: Precisión tras ronda 14 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 15\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 15 = 0.77\n",
      "Cliente 1: Precisión tras ronda 15 = 0.85\n",
      "Cliente 2: Precisión tras ronda 15 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 16\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 16 = 0.78\n",
      "Cliente 1: Precisión tras ronda 16 = 0.85\n",
      "Cliente 2: Precisión tras ronda 16 = 0.72\n",
      "\n",
      "Ronda de aprendizaje federado 17\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 17 = 0.78\n",
      "Cliente 1: Precisión tras ronda 17 = 0.85\n",
      "Cliente 2: Precisión tras ronda 17 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 18\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 18 = 0.78\n",
      "Cliente 1: Precisión tras ronda 18 = 0.85\n",
      "Cliente 2: Precisión tras ronda 18 = 0.76\n",
      "\n",
      "Ronda de aprendizaje federado 19\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 19 = 0.79\n",
      "Cliente 1: Precisión tras ronda 19 = 0.85\n",
      "Cliente 2: Precisión tras ronda 19 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 20\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 20 = 0.76\n",
      "Cliente 1: Precisión tras ronda 20 = 0.85\n",
      "Cliente 2: Precisión tras ronda 20 = 0.76\n",
      "\n",
      "Resultados del entrenamiento en la última ronda:\n",
      "Cliente 0: Precisión = 0.76\n",
      "Cliente 1: Precisión = 0.85\n",
      "Cliente 2: Precisión = 0.76\n",
      "Jain Index global tras la última ronda: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar entrenamiento federado iterativo\n",
    "final_local_accuracies_fedavg = train_federated_with_fedavg_lightgbm(clients_data, local_models_lightgbm, rounds=20, epsilon=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el rendimiento local inicial usando GBM\n",
    "def evaluate_local_models_gbm(clients_data, epsilon=None):\n",
    "    local_accuracies = []\n",
    "    for client_id, (X, y) in enumerate(clients_data):\n",
    "        # Añadir privacidad diferencial si se especifica\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        local_accuracies.append((client_id, accuracy, model))\n",
    "        print(f\"Cliente {client_id}: Precisión inicial = {accuracy:.2f}\")\n",
    "    return local_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente 0: Precisión inicial = 0.80\n",
      "Cliente 1: Precisión inicial = 0.85\n",
      "Cliente 2: Precisión inicial = 0.79\n"
     ]
    }
   ],
   "source": [
    "# Reemplaza la evaluación inicial con la función GBM\n",
    "local_models_gbm = evaluate_local_models_gbm(clients_data, epsilon=5)  # Privacidad diferencial aplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado con Federated Averaging\n",
    "def federated_averaging(local_models):\n",
    "    \"\"\" Combina los pesos de los modelos locales utilizando Federated Averaging. \"\"\"\n",
    "    print(\"Federated Averaging aplicado exitosamente.\")\n",
    "    combined_model = GradientBoostingClassifier()  # Simulación básica\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado modificado para GBM\n",
    "def federated_learning_round_gbm(local_models, clients_data):\n",
    "    combined_model = GradientBoostingClassifier()\n",
    "    X_sample, y_sample = clients_data[0]  # Datos del cliente 0 como ejemplo\n",
    "    combined_model.fit(X_sample, y_sample)\n",
    "    print(\"Modelo combinado ajustado preliminarmente\")\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento federado iterativo con Federated Averaging\n",
    "def train_federated_with_fedavg_gbm(clients_data, local_models, rounds=20, epsilon=None):\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "        # Realizamos Federated Averaging en el servidor central\n",
    "        combined_model = federated_averaging(local_models)\n",
    "        \n",
    "        if combined_model is None:\n",
    "            raise ValueError(\"El modelo combinado no se ha creado correctamente.\")\n",
    "        \n",
    "        # Redistribuir el modelo combinado y continuar entrenando localmente\n",
    "        local_accuracies_after = []\n",
    "        for client_id, (X, y) in enumerate(clients_data):\n",
    "            if epsilon is not None:\n",
    "                X = add_differential_privacy(X, epsilon=epsilon)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            combined_model.fit(X_train, y_train)  # Ajustamos el modelo combinado localmente\n",
    "            y_pred = combined_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            local_accuracies_after.append((client_id, accuracy, combined_model))\n",
    "            print(f\"Cliente {client_id}: Precisión tras ronda {round_idx + 1} = {accuracy:.2f}\")\n",
    "        \n",
    "        # Actualizamos los modelos locales con los nuevos\n",
    "        local_models = local_accuracies_after\n",
    "\n",
    "    # Mostrar resultados por cliente y calcular el Jain Index global\n",
    "    print(\"\\nResultados del entrenamiento en la última ronda:\")\n",
    "    accuracies = []\n",
    "    for client_id, accuracy, model in local_models:\n",
    "        print(f\"Cliente {client_id}: Precisión = {accuracy:.2f}\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    jain_index = calculate_jain_index(accuracies)  # Calcular el Jain Index para todas las precisiones\n",
    "    print(f\"Jain Index global tras la última ronda: {jain_index:.2f}\")\n",
    "\n",
    "    return local_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ronda de aprendizaje federado 1\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 1 = 0.71\n",
      "Cliente 1: Precisión tras ronda 1 = 0.81\n",
      "Cliente 2: Precisión tras ronda 1 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 2\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 2 = 0.71\n",
      "Cliente 1: Precisión tras ronda 2 = 0.81\n",
      "Cliente 2: Precisión tras ronda 2 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 3\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 3 = 0.70\n",
      "Cliente 1: Precisión tras ronda 3 = 0.81\n",
      "Cliente 2: Precisión tras ronda 3 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 4\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 4 = 0.71\n",
      "Cliente 1: Precisión tras ronda 4 = 0.81\n",
      "Cliente 2: Precisión tras ronda 4 = 0.77\n",
      "\n",
      "Ronda de aprendizaje federado 5\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 5 = 0.73\n",
      "Cliente 1: Precisión tras ronda 5 = 0.81\n",
      "Cliente 2: Precisión tras ronda 5 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 6\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 6 = 0.72\n",
      "Cliente 1: Precisión tras ronda 6 = 0.81\n",
      "Cliente 2: Precisión tras ronda 6 = 0.81\n",
      "\n",
      "Ronda de aprendizaje federado 7\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 7 = 0.71\n",
      "Cliente 1: Precisión tras ronda 7 = 0.81\n",
      "Cliente 2: Precisión tras ronda 7 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 8\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 8 = 0.70\n",
      "Cliente 1: Precisión tras ronda 8 = 0.81\n",
      "Cliente 2: Precisión tras ronda 8 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 9\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 9 = 0.73\n",
      "Cliente 1: Precisión tras ronda 9 = 0.81\n",
      "Cliente 2: Precisión tras ronda 9 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 10\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 10 = 0.70\n",
      "Cliente 1: Precisión tras ronda 10 = 0.81\n",
      "Cliente 2: Precisión tras ronda 10 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 11\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 11 = 0.72\n",
      "Cliente 1: Precisión tras ronda 11 = 0.81\n",
      "Cliente 2: Precisión tras ronda 11 = 0.69\n",
      "\n",
      "Ronda de aprendizaje federado 12\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 12 = 0.73\n",
      "Cliente 1: Precisión tras ronda 12 = 0.81\n",
      "Cliente 2: Precisión tras ronda 12 = 0.74\n",
      "\n",
      "Ronda de aprendizaje federado 13\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 13 = 0.73\n",
      "Cliente 1: Precisión tras ronda 13 = 0.81\n",
      "Cliente 2: Precisión tras ronda 13 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 14\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 14 = 0.70\n",
      "Cliente 1: Precisión tras ronda 14 = 0.81\n",
      "Cliente 2: Precisión tras ronda 14 = 0.74\n",
      "\n",
      "Ronda de aprendizaje federado 15\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 15 = 0.72\n",
      "Cliente 1: Precisión tras ronda 15 = 0.81\n",
      "Cliente 2: Precisión tras ronda 15 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 16\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 16 = 0.74\n",
      "Cliente 1: Precisión tras ronda 16 = 0.81\n",
      "Cliente 2: Precisión tras ronda 16 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 17\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 17 = 0.71\n",
      "Cliente 1: Precisión tras ronda 17 = 0.81\n",
      "Cliente 2: Precisión tras ronda 17 = 0.68\n",
      "\n",
      "Ronda de aprendizaje federado 18\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 18 = 0.70\n",
      "Cliente 1: Precisión tras ronda 18 = 0.81\n",
      "Cliente 2: Precisión tras ronda 18 = 0.75\n",
      "\n",
      "Ronda de aprendizaje federado 19\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 19 = 0.72\n",
      "Cliente 1: Precisión tras ronda 19 = 0.81\n",
      "Cliente 2: Precisión tras ronda 19 = 0.74\n",
      "\n",
      "Ronda de aprendizaje federado 20\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 20 = 0.72\n",
      "Cliente 1: Precisión tras ronda 20 = 0.81\n",
      "Cliente 2: Precisión tras ronda 20 = 0.70\n",
      "\n",
      "Resultados del entrenamiento en la última ronda:\n",
      "Cliente 0: Precisión = 0.72\n",
      "Cliente 1: Precisión = 0.81\n",
      "Cliente 2: Precisión = 0.70\n",
      "Jain Index global tras la última ronda: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar entrenamiento federado iterativo\n",
    "final_local_accuracies_fedavg = train_federated_with_fedavg_gbm(clients_data, local_models_gbm, rounds=20, epsilon=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el rendimiento local inicial usando AdaBoost\n",
    "def evaluate_local_models_adaboost(clients_data, epsilon=None):\n",
    "    local_accuracies = []\n",
    "    for client_id, (X, y) in enumerate(clients_data):\n",
    "        # Añadir privacidad diferencial si se especifica\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        model = AdaBoostClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        local_accuracies.append((client_id, accuracy, model))\n",
    "        print(f\"Cliente {client_id}: Precisión inicial = {accuracy:.2f}\")\n",
    "    return local_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente 0: Precisión inicial = 0.79\n",
      "Cliente 1: Precisión inicial = 0.83\n",
      "Cliente 2: Precisión inicial = 0.77\n"
     ]
    }
   ],
   "source": [
    "# Reemplaza la evaluación inicial con la función AdaBoost\n",
    "local_models_adaboost = evaluate_local_models_adaboost(clients_data, epsilon=5)  # Privacidad diferencial aplicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente 0: Precisión inicial = 0.61\n",
      "Cliente 1: Precisión inicial = 0.76\n",
      "Cliente 2: Precisión inicial = 0.64\n"
     ]
    }
   ],
   "source": [
    "local_models_adaboost = evaluate_local_models_adaboost(clients_data, epsilon=1.0)\n",
    "initial_accuracies = [accuracy for _, accuracy, _ in local_models_adaboost]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_local_models_adaboost(clients_data, epsilon=None):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento local inicial usando AdaBoost.\n",
    "    \n",
    "    :param clients_data: Lista de datos para cada cliente (features y labels).\n",
    "    :param epsilon: Parámetro de privacidad diferencial (opcional).\n",
    "    :return: Lista de precisiones iniciales y modelos por cliente.\n",
    "    \"\"\"\n",
    "    local_accuracies = []\n",
    "    for client_id, (X, y) in enumerate(clients_data):\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        model = AdaBoostClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        local_accuracies.append((client_id, accuracy, model))\n",
    "        print(f\"Cliente {client_id}: Precisión inicial = {accuracy:.2f}\")\n",
    "    return local_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado con Federated Averaging\n",
    "def federated_averaging(local_models):\n",
    "    \"\"\" Combina los pesos de los modelos locales utilizando Federated Averaging. \"\"\"\n",
    "    print(\"Federated Averaging aplicado exitosamente.\")\n",
    "    combined_model = AdaBoostClassifier()  # Simulación básica\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de aprendizaje federado modificado para AdaBoost\n",
    "def federated_learning_round_adaboost(local_models, clients_data):\n",
    "    combined_model = AdaBoostClassifier()\n",
    "    X_sample, y_sample = clients_data[0]  # Datos del cliente 0 como ejemplo\n",
    "    combined_model.fit(X_sample, y_sample)\n",
    "    print(\"Modelo combinado ajustado preliminarmente\")\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento federado iterativo con Federated Averaging\n",
    "def train_federated_with_fedavg_adaboost(clients_data, local_models, rounds=20, epsilon=None):\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "        # Realizamos Federated Averaging en el servidor central\n",
    "        combined_model = federated_averaging(local_models)\n",
    "        \n",
    "        if combined_model is None:\n",
    "            raise ValueError(\"El modelo combinado no se ha creado correctamente.\")\n",
    "        \n",
    "        # Redistribuir el modelo combinado y continuar entrenando localmente\n",
    "        local_accuracies_after = []\n",
    "        for client_id, (X, y) in enumerate(clients_data):\n",
    "            if epsilon is not None:\n",
    "                X = add_differential_privacy(X, epsilon=epsilon)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            combined_model.fit(X_train, y_train)  # Ajustamos el modelo combinado localmente\n",
    "            y_pred = combined_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            local_accuracies_after.append((client_id, accuracy, combined_model))\n",
    "            print(f\"Cliente {client_id}: Precisión tras ronda {round_idx + 1} = {accuracy:.2f}\")\n",
    "        \n",
    "        # Actualizamos los modelos locales con los nuevos\n",
    "        local_models = local_accuracies_after\n",
    "\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jain_index(values):\n",
    "    \"\"\"\n",
    "    Calcula el Jain Index para evaluar la equidad en la distribución de recursos.\n",
    "    \n",
    "    :param values: Lista o arreglo de valores a evaluar (e.g., precisión de modelos locales).\n",
    "    :return: Jain Index.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    numerator = np.sum(values) ** 2\n",
    "    denominator = len(values) * np.sum(values ** 2)\n",
    "    return numerator / denominator if denominator != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_federated_with_fedavg_adaboost(clients_data, local_models, rounds=20, epsilon=None):\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "        # Realizamos Federated Averaging en el servidor central\n",
    "        combined_model = federated_averaging(local_models)\n",
    "        \n",
    "        local_accuracies_after = []\n",
    "        for client_id, (X, y) in enumerate(clients_data):\n",
    "            if epsilon is not None:\n",
    "                X = add_differential_privacy(X, epsilon=epsilon)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "            combined_model.fit(X_train, y_train)\n",
    "            y_pred = combined_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            local_accuracies_after.append((client_id, accuracy, combined_model))\n",
    "            print(f\"Cliente {client_id}: Precisión tras ronda {round_idx + 1} = {accuracy:.2f}\")\n",
    "        \n",
    "        local_models = local_accuracies_after\n",
    "    \n",
    "    # Mostrar resultados por cliente y calcular el Jain Index global\n",
    "    print(\"\\nResultados del entrenamiento en la última ronda:\")\n",
    "    accuracies = []\n",
    "    for client_id, accuracy, model in local_models:\n",
    "        print(f\"Cliente {client_id}: Precisión = {accuracy:.2f}\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    jain_index = calculate_jain_index(accuracies)  # Calcular el Jain Index para todas las precisiones\n",
    "    print(f\"Jain Index global tras la última ronda: {jain_index:.2f}\")\n",
    "\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ronda de aprendizaje federado 1\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 1 = 0.62\n",
      "Cliente 1: Precisión tras ronda 1 = 0.76\n",
      "Cliente 2: Precisión tras ronda 1 = 0.73\n",
      "\n",
      "Ronda de aprendizaje federado 2\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 2 = 0.61\n",
      "Cliente 1: Precisión tras ronda 2 = 0.76\n",
      "Cliente 2: Precisión tras ronda 2 = 0.67\n",
      "\n",
      "Ronda de aprendizaje federado 3\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 3 = 0.61\n",
      "Cliente 1: Precisión tras ronda 3 = 0.76\n",
      "Cliente 2: Precisión tras ronda 3 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 4\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 4 = 0.63\n",
      "Cliente 1: Precisión tras ronda 4 = 0.76\n",
      "Cliente 2: Precisión tras ronda 4 = 0.67\n",
      "\n",
      "Ronda de aprendizaje federado 5\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 5 = 0.60\n",
      "Cliente 1: Precisión tras ronda 5 = 0.76\n",
      "Cliente 2: Precisión tras ronda 5 = 0.68\n",
      "\n",
      "Ronda de aprendizaje federado 6\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 6 = 0.62\n",
      "Cliente 1: Precisión tras ronda 6 = 0.76\n",
      "Cliente 2: Precisión tras ronda 6 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 7\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 7 = 0.63\n",
      "Cliente 1: Precisión tras ronda 7 = 0.76\n",
      "Cliente 2: Precisión tras ronda 7 = 0.68\n",
      "\n",
      "Ronda de aprendizaje federado 8\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 8 = 0.63\n",
      "Cliente 1: Precisión tras ronda 8 = 0.76\n",
      "Cliente 2: Precisión tras ronda 8 = 0.67\n",
      "\n",
      "Ronda de aprendizaje federado 9\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 9 = 0.62\n",
      "Cliente 1: Precisión tras ronda 9 = 0.76\n",
      "Cliente 2: Precisión tras ronda 9 = 0.69\n",
      "\n",
      "Ronda de aprendizaje federado 10\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 10 = 0.61\n",
      "Cliente 1: Precisión tras ronda 10 = 0.76\n",
      "Cliente 2: Precisión tras ronda 10 = 0.68\n",
      "\n",
      "Ronda de aprendizaje federado 11\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 11 = 0.61\n",
      "Cliente 1: Precisión tras ronda 11 = 0.76\n",
      "Cliente 2: Precisión tras ronda 11 = 0.68\n",
      "\n",
      "Ronda de aprendizaje federado 12\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 12 = 0.62\n",
      "Cliente 1: Precisión tras ronda 12 = 0.76\n",
      "Cliente 2: Precisión tras ronda 12 = 0.65\n",
      "\n",
      "Ronda de aprendizaje federado 13\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 13 = 0.62\n",
      "Cliente 1: Precisión tras ronda 13 = 0.76\n",
      "Cliente 2: Precisión tras ronda 13 = 0.66\n",
      "\n",
      "Ronda de aprendizaje federado 14\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 14 = 0.63\n",
      "Cliente 1: Precisión tras ronda 14 = 0.76\n",
      "Cliente 2: Precisión tras ronda 14 = 0.71\n",
      "\n",
      "Ronda de aprendizaje federado 15\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 15 = 0.63\n",
      "Cliente 1: Precisión tras ronda 15 = 0.76\n",
      "Cliente 2: Precisión tras ronda 15 = 0.64\n",
      "\n",
      "Ronda de aprendizaje federado 16\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 16 = 0.60\n",
      "Cliente 1: Precisión tras ronda 16 = 0.76\n",
      "Cliente 2: Precisión tras ronda 16 = 0.63\n",
      "\n",
      "Ronda de aprendizaje federado 17\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 17 = 0.63\n",
      "Cliente 1: Precisión tras ronda 17 = 0.76\n",
      "Cliente 2: Precisión tras ronda 17 = 0.67\n",
      "\n",
      "Ronda de aprendizaje federado 18\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 18 = 0.62\n",
      "Cliente 1: Precisión tras ronda 18 = 0.76\n",
      "Cliente 2: Precisión tras ronda 18 = 0.64\n",
      "\n",
      "Ronda de aprendizaje federado 19\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 19 = 0.60\n",
      "Cliente 1: Precisión tras ronda 19 = 0.76\n",
      "Cliente 2: Precisión tras ronda 19 = 0.70\n",
      "\n",
      "Ronda de aprendizaje federado 20\n",
      "Federated Averaging aplicado exitosamente.\n",
      "Cliente 0: Precisión tras ronda 20 = 0.61\n",
      "Cliente 1: Precisión tras ronda 20 = 0.76\n",
      "Cliente 2: Precisión tras ronda 20 = 0.70\n",
      "\n",
      "Resultados del entrenamiento en la última ronda:\n",
      "Cliente 0: Precisión = 0.61\n",
      "Cliente 1: Precisión = 0.76\n",
      "Cliente 2: Precisión = 0.70\n",
      "Jain Index global tras la última ronda: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar entrenamiento federado iterativo\n",
    "final_local_accuracies_fedavg = train_federated_with_fedavg_adaboost(clients_data, local_models_adaboost, rounds=20, epsilon=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y mejora del modelo Global (servidor central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data_global = [(X1, y1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de datos sintéticos para clientes\n",
    "#def generate_synthetic_data(size=100):\n",
    "#    X = np.random.rand(size, 5)\n",
    "#    y = (X.sum(axis=1) > 2.5).astype(int)\n",
    "#    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sintéticos para evaluación del modelo global\n",
    "#def generate_global_evaluation_data(size=300):\n",
    "#    X = np.random.rand(size, 5)\n",
    "#    y = (X.sum(axis=1) > 2.5).astype(int)\n",
    "#    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para añadir privacidad diferencial usando ruido Laplaciano\n",
    "def add_differential_privacy(data, epsilon=1.0):\n",
    "    noise = np.random.laplace(loc=0, scale=1/epsilon, size=data.shape)\n",
    "    private_data = data + noise\n",
    "    return private_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Global Model without Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model_initial(client_data, epsilon=None):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo global inicial utilizando los datos de un solo cliente.\n",
    "    :param client_data: Conjunto de datos del cliente en formato (X, y).\n",
    "    :param epsilon: Parámetro para añadir privacidad diferencial (opcional).\n",
    "    :return: Precisión inicial y modelo global inicial.\n",
    "    \"\"\"\n",
    "    X, y = client_data  # Desempaquetar datos del cliente\n",
    "\n",
    "    # Añadir privacidad diferencial si se especifica\n",
    "    if epsilon is not None:\n",
    "        X = add_differential_privacy(X, epsilon=epsilon)\n",
    "\n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Inicializar y entrenar el modelo\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión inicial del modelo global (Cliente único) = {accuracy:.2f}\")\n",
    "    \n",
    "    return accuracy, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo global = 0.58\n",
      "Evaluación final del modelo global: Precisión = 0.58\n"
     ]
    }
   ],
   "source": [
    "def evaluate_global_model(global_model, client_data, epsilon=None):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento del modelo global usando los datos del cliente 1.\n",
    "    :param global_model: Modelo global entrenado.\n",
    "    :param client_data: Conjunto de datos del cliente en formato (X, y).\n",
    "    :param epsilon: Parámetro para añadir privacidad diferencial (opcional).\n",
    "    :return: Precisión del modelo global.\n",
    "    \"\"\"\n",
    "    X, y = client_data\n",
    "\n",
    "    # Añadir privacidad diferencial si se especifica\n",
    "    if epsilon is not None:\n",
    "        X = add_differential_privacy(X, epsilon=epsilon)\n",
    "    \n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Entrenar el modelo global si no está entrenado\n",
    "    global_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_pred = global_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión del modelo global = {accuracy:.2f}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Entrenamiento y Evaluación del Modelo Global\n",
    "# Cargar los datos del cliente 1 preprocesado (X, y)\n",
    "X1, y1 = client1_preprocessed.drop(columns=[' loan_status']), client1_preprocessed[' loan_status']\n",
    "client_data = (X1, y1)\n",
    "\n",
    "# Inicializar el modelo global\n",
    "global_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Evaluar el modelo global\n",
    "global_accuracy = evaluate_global_model(global_model, client_data, epsilon=1.0)\n",
    "\n",
    "print(f\"Evaluación final del modelo global: Precisión = {global_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de Federated Learning con evaluación global\n",
    "def federated_averaging(local_models):\n",
    "    \"\"\"\n",
    "    Simula Federated Averaging para combinar modelos locales.\n",
    "    :param local_models: Modelos locales y métricas.\n",
    "    :return: Modelo combinado global.\n",
    "    \"\"\"\n",
    "    combined_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "    print(\"Modelo global actualizado mediante Federated Averaging.\")\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_federated_with_global_evaluation(clients_data, global_model, rounds=20, epsilon=None):\n",
    "    \"\"\"\n",
    "    Entrenamiento federado iterativo con evaluación global en cada ronda.\n",
    "    :param clients_data: Lista de conjuntos de datos de clientes (X, y).\n",
    "    :param global_model: Modelo global inicial.\n",
    "    :param rounds: Número de rondas de aprendizaje federado.\n",
    "    :param epsilon: Parámetro para añadir privacidad diferencial (opcional).\n",
    "    :return: Historial de precisiones globales por ronda.\n",
    "    \"\"\"\n",
    "    global_accuracies = []  # Historial de precisiones del modelo global\n",
    "\n",
    "    for round_idx in range(rounds):\n",
    "        print(f\"\\nRonda de aprendizaje federado {round_idx + 1}\")\n",
    "\n",
    "        # --- Federated Averaging ---\n",
    "        combined_model = federated_averaging([global_model])  # Actualizamos el modelo global\n",
    "        \n",
    "        if combined_model is None:\n",
    "            raise ValueError(\"El modelo combinado no se ha creado correctamente.\")\n",
    "\n",
    "        # --- Evaluar el rendimiento del modelo global ---\n",
    "        # Usamos los datos del cliente 1 (client1_preprocessed) para evaluar\n",
    "        X, y = clients_data[0]\n",
    "        if epsilon is not None:\n",
    "            X = add_differential_privacy(X, epsilon=epsilon)\n",
    "        \n",
    "        # Dividir los datos en entrenamiento y prueba para evaluación\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Entrenar el modelo global y evaluar en el conjunto de prueba\n",
    "        combined_model.fit(X_train, y_train)\n",
    "        y_pred = combined_model.predict(X_test)\n",
    "        global_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        global_accuracies.append(global_accuracy)\n",
    "        print(f\"Precisión del modelo global tras ronda {round_idx + 1} = {global_accuracy:.2f}\")\n",
    "\n",
    "    return global_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ronda de aprendizaje federado 1\n",
      "Modelo global actualizado mediante Federated Averaging.\n",
      "Precisión del modelo global tras ronda 1 = 0.58\n",
      "\n",
      "Ronda de aprendizaje federado 2\n",
      "Modelo global actualizado mediante Federated Averaging.\n",
      "Precisión del modelo global tras ronda 2 = 0.61\n",
      "\n",
      "Ronda de aprendizaje federado 3\n",
      "Modelo global actualizado mediante Federated Averaging.\n",
      "Precisión del modelo global tras ronda 3 = 0.59\n",
      "\n",
      "Ronda de aprendizaje federado 4\n",
      "Modelo global actualizado mediante Federated Averaging.\n",
      "Precisión del modelo global tras ronda 4 = 0.60\n",
      "\n",
      "Ronda de aprendizaje federado 5\n",
      "Modelo global actualizado mediante Federated Averaging.\n",
      "Precisión del modelo global tras ronda 5 = 0.62\n",
      "\n",
      "Historial de precisiones globales por ronda: [0.5807962529274004, 0.6073380171740828, 0.5932864949258392, 0.5956284153005464, 0.6167056986729118]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "# Preparar los datos del cliente 1 preprocesado\n",
    "X1, y1 = client1_preprocessed.drop(columns=[' loan_status']), client1_preprocessed[' loan_status']\n",
    "clients_data = [(X1, y1)]\n",
    "\n",
    "# Inicializar el modelo global\n",
    "global_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Entrenar el modelo con aprendizaje federado y evaluar el rendimiento global\n",
    "global_accuracies = train_federated_with_global_evaluation(clients_data, global_model, rounds=5, epsilon=1.0)\n",
    "\n",
    "# Imprimir el historial de precisiones globales\n",
    "print(f\"\\nHistorial de precisiones globales por ronda: {global_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparativa de varios enfoques de Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio absoluto (MAE) por enfoque:\n",
      "FedAvg: 0.0840\n",
      "DFedAvg: 0.0848\n",
      "FedMA: 0.0840\n",
      "FedAvg-Z: 0.3476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generar datos ficticios\n",
    "def generate_data(num_clients, num_samples, noise=0.1):\n",
    "    data = []\n",
    "    for _ in range(num_clients):\n",
    "        x = np.random.rand(num_samples)\n",
    "        y = 3 * x + 2 + np.random.normal(0, noise, num_samples)  # y = 3x + 2 con ruido\n",
    "        data.append((x, y))\n",
    "    return data\n",
    "\n",
    "# Simular entrenamiento local y retornar un modelo local (coeficientes)\n",
    "def train_local_model(data):\n",
    "    x, y = data\n",
    "    w = np.polyfit(x, y, 1)  # Ajuste lineal\n",
    "    return w\n",
    "\n",
    "# Federated Averaging (FedAvg)\n",
    "def fed_avg(local_models):\n",
    "    return np.mean(local_models, axis=0)\n",
    "\n",
    "# Decentralized Federated Averaging (DFedAvg)\n",
    "def dfed_avg(local_models):\n",
    "    return np.median(local_models, axis=0)\n",
    "\n",
    "# Federated Matched Averaging (FedMA) - Aproximación simplificada\n",
    "def fed_ma(local_models):\n",
    "    return np.average(local_models, axis=0, weights=np.linspace(1, 2, len(local_models)))\n",
    "\n",
    "# FedAvg-Z con penalización adaptativa\n",
    "def fed_avg_z(local_models, penalty=0.9): #Modificar la penalidad segun corresponda \n",
    "    adjusted_models = [model * penalty for model in local_models]\n",
    "    return np.mean(adjusted_models, axis=0)\n",
    "\n",
    "# Calcular el error medio absoluto (MAE)\n",
    "def calculate_mae(model, data):\n",
    "    errors = []\n",
    "    for x, y in data:\n",
    "        predictions = model[0] * x + model[1]\n",
    "        errors.append(np.abs(predictions - y))\n",
    "    return np.mean(errors)\n",
    "\n",
    "# Configuración\n",
    "num_clients = 5\n",
    "num_samples = 50\n",
    "data = generate_data(num_clients, num_samples)\n",
    "\n",
    "# Entrenamiento local\n",
    "local_models = [train_local_model(client_data) for client_data in data]\n",
    "\n",
    "# Combinar modelos con cada enfoque\n",
    "fedavg_model = fed_avg(local_models)\n",
    "dfedavg_model = dfed_avg(local_models)\n",
    "fedma_model = fed_ma(local_models)\n",
    "fedavgz_model = fed_avg_z(local_models)\n",
    "\n",
    "# Calcular MAE para cada enfoque\n",
    "fedavg_mae = calculate_mae(fedavg_model, data)\n",
    "dfedavg_mae = calculate_mae(dfedavg_model, data)\n",
    "fedma_mae = calculate_mae(fedma_model, data)\n",
    "fedavgz_mae = calculate_mae(fedavgz_model, data)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Error medio absoluto (MAE) por enfoque:\")\n",
    "print(f\"FedAvg: {fedavg_mae:.4f}\")\n",
    "print(f\"DFedAvg: {dfedavg_mae:.4f}\")\n",
    "print(f\"FedMA: {fedma_mae:.4f}\")\n",
    "print(f\"FedAvg-Z: {fedavgz_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio absoluto (MAE) por enfoque:\n",
      "FedAvg: 0.4287\n",
      "DFedAvg: 0.4911\n",
      "FedMA: 0.4609\n",
      "FedAvg-Z: 0.3869\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Función para determinar las columnas relevantes (numéricas)\n",
    "def extract_features_and_labels(data):\n",
    "    # Filtrar columnas numéricas\n",
    "    numeric_columns = data.select_dtypes(include=[\"number\"]).columns\n",
    "    if len(numeric_columns) < 2:\n",
    "        raise ValueError(\"No hay suficientes columnas numéricas para usar como características y etiquetas.\")\n",
    "    # Usar la primera columna numérica como característica (x)\n",
    "    x = data[numeric_columns[0]].values\n",
    "    # Usar la segunda columna numérica como etiqueta (y)\n",
    "    y = data[numeric_columns[1]].values\n",
    "    return x, y\n",
    "\n",
    "# Simular entrenamiento local y retornar un modelo local (coeficientes)\n",
    "def train_local_model(data):\n",
    "    x, y = extract_features_and_labels(data)\n",
    "    w = np.polyfit(x, y, 1)  # Ajuste lineal\n",
    "    return w\n",
    "\n",
    "# Federated Averaging (FedAvg)\n",
    "def fed_avg(local_models):\n",
    "    return np.mean(local_models, axis=0)\n",
    "\n",
    "# Decentralized Federated Averaging (DFedAvg)\n",
    "def dfed_avg(local_models):\n",
    "    return np.median(local_models, axis=0)\n",
    "\n",
    "# Federated Matched Averaging (FedMA) - Aproximación simplificada\n",
    "def fed_ma(local_models):\n",
    "    return np.average(local_models, axis=0, weights=np.linspace(1, 2, len(local_models)))\n",
    "\n",
    "# FedAvg-Z con penalización adaptativa\n",
    "def fed_avg_z(local_models, penalty=0.9):\n",
    "    adjusted_models = [model * penalty for model in local_models]\n",
    "    return np.mean(adjusted_models, axis=0)\n",
    "\n",
    "# Calcular el error medio absoluto (MAE)\n",
    "def calculate_mae(model, dataframes):\n",
    "    errors = []\n",
    "    for df in dataframes:\n",
    "        x, y = extract_features_and_labels(df)\n",
    "        assert len(x) == len(y), \"x e y tienen longitudes diferentes.\"\n",
    "        predictions = model[0] * x + model[1]\n",
    "        errors.extend(np.abs(predictions - y))  # Agregar errores individuales\n",
    "    return np.mean(errors)\n",
    "\n",
    "# Usa los datasets preprocesados directamente\n",
    "dataframes = [client1_preprocessed, client2_preprocessed, client3_preprocessed]\n",
    "\n",
    "# Entrenamiento local para cada cliente\n",
    "local_models = [train_local_model(df) for df in dataframes]\n",
    "\n",
    "# Combinar modelos con cada enfoque\n",
    "fedavg_model = fed_avg(local_models)\n",
    "dfedavg_model = dfed_avg(local_models)\n",
    "fedma_model = fed_ma(local_models)\n",
    "fedavgz_model = fed_avg_z(local_models)\n",
    "\n",
    "# Calcular MAE para cada enfoque\n",
    "fedavg_mae = calculate_mae(fedavg_model, dataframes)\n",
    "dfedavg_mae = calculate_mae(dfedavg_model, dataframes)\n",
    "fedma_mae = calculate_mae(fedma_model, dataframes)\n",
    "fedavgz_mae = calculate_mae(fedavgz_model, dataframes)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Error medio absoluto (MAE) por enfoque:\")\n",
    "print(f\"FedAvg: {fedavg_mae:.4f}\")\n",
    "print(f\"DFedAvg: {dfedavg_mae:.4f}\")\n",
    "print(f\"FedMA: {fedma_mae:.4f}\")\n",
    "print(f\"FedAvg-Z: {fedavgz_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FedAvg y FedMA (MAE: 0.0840):\n",
    "- Estos enfoques obtuvieron el mejor rendimiento en tu prueba, destacándose por su precisión.\n",
    "- FedAvg, con su simplicidad, demuestra ser confiable para este conjunto de datos homogéneos.\n",
    "- FedMA iguala a FedAvg, lo cual sugiere que el uso de pesos para combinar modelos locales es efectivo en este caso.\n",
    "\n",
    "#### DFedAvg (MAE: 0.0848):\n",
    "- Aunque el error es ligeramente mayor que el de FedAvg y FedMA, sigue siendo competitivo.\n",
    "- Su enfoque descentralizado podría tener beneficios adicionales, como la reducción de la dependencia de un servidor central, lo que aumenta su utilidad en entornos específicos.\n",
    "\n",
    "#### FedAvg-Z (MAE: 0.3476):\n",
    "- Este enfoque muestra un rendimiento significativamente peor, lo que indica que la penalización adaptativa afectó negativamente la agregación de modelos.\n",
    "- Esto podría deberse a una configuración excesiva del factor de penalización. Ajustar este parámetro (por ejemplo, reducirlo a 0.7 o 0.5) podría mejorar el rendimiento.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoque Centralizado vs Descentralizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "client1_data = pd.read_csv('client1/loan_approval_dataset.csv')\n",
    "client2_data = pd.read_csv('client2/Loan_Default.csv')\n",
    "client3_data = pd.read_csv('client3/loan_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas de etiquetas para que sean consistentes\n",
    "client1_data.rename(columns={' loan_status': 'target'}, inplace=True)\n",
    "client2_data.rename(columns={'Status': 'target'}, inplace=True)\n",
    "client3_data.rename(columns={'Loan_Status': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'approval' a 1 y 'rejected' a 0\n",
    "client1_data['target'] = client1_data['target'].map({'Approval': 1, 'Rejected': 0})\n",
    "client3_data['target'] = client3_data['target'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir cada columna categórica en numérica\n",
    "for column in client1_data.columns:\n",
    "    if client1_data[column].dtype == 'object':\n",
    "        client1_data[column] = label_encoder.fit_transform(client1_data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir cada columna categórica en numérica\n",
    "for column in client2_data.columns:\n",
    "    if client2_data[column].dtype == 'object':\n",
    "        client2_data[column] = label_encoder.fit_transform(client2_data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir cada columna categórica en numérica\n",
    "for column in client3_data.columns:\n",
    "    if client3_data[column].dtype == 'object':\n",
    "        client3_data[column] = label_encoder.fit_transform(client3_data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las etiquetas a categóricas\n",
    "client1_data['target'] = client1_data['target'].astype('category')\n",
    "client2_data['target'] = client2_data['target'].astype('category')\n",
    "client3_data['target'] = client3_data['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m client1_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m client1_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m client1_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mclient1_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:577\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert float NaN to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    580\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    582\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    583\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    584\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "client1_data['target'] = client1_data['target'].replace([np.nan, np.inf, -np.inf], 0)\n",
    "client1_data['target'] = client1_data['target'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar los datasets para el entrenamiento centralizado\n",
    "combined_data = pd.concat([client1_data, client2_data, client3_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "combined_data_imputed = pd.DataFrame(imputer.fit_transform(combined_data), columns=combined_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características y la etiqueta\n",
    "X_combined = combined_data_imputed.drop('target', axis=1)\n",
    "y_combined = combined_data_imputed['target']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 29540, number of negative: 93116\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4563\n",
      "[LightGBM] [Info] Number of data points in the train set: 122656, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240836 -> initscore=-1.148101\n",
      "[LightGBM] [Info] Start training from score -1.148101\n"
     ]
    }
   ],
   "source": [
    "# Inicializar los modelos\n",
    "models = {\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(),\n",
    "    'LightGBM': lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# Entrenar y evaluar los modelos centralizados\n",
    "centralized_results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_combined, y_train_combined)\n",
    "    y_pred_combined = model.predict(X_test_combined)\n",
    "    accuracy = accuracy_score(y_test_combined, y_pred_combined)\n",
    "    centralized_results[model_name] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar modelos descentralizados\n",
    "def train_evaluate_decentralized(client_data):\n",
    "    client_data = pd.get_dummies(client_data)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    client_data_imputed = pd.DataFrame(imputer.fit_transform(client_data), columns=client_data.columns)\n",
    "    X_client = client_data_imputed.drop('target', axis=1)\n",
    "    y_client = client_data_imputed['target']\n",
    "    \n",
    "    # Intentar dividir los datos hasta que y_train tenga al menos dos clases\n",
    "    for _ in range(10):  # Intentar hasta 10 veces\n",
    "        X_train_client, X_test_client, y_train_client, y_test_client = train_test_split(X_client, y_client, test_size=0.2, random_state=42, stratify=y_client)\n",
    "        if len(y_train_client.unique()) > 1:\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"El conjunto de datos contiene menos de dos clases después de la división.\")\n",
    "    \n",
    "    client_results = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_client, y_train_client)\n",
    "        y_pred_client = model.predict(X_test_client)\n",
    "        accuracy = accuracy_score(y_test_client, y_pred_client)\n",
    "        client_results[model_name] = accuracy\n",
    "    \n",
    "    return client_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate_decentralized_models(X, y, clients):\n",
    "    # Dividir los datos hasta que y_train tenga al menos dos clases\n",
    "    while True:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        if len(np.unique(y_train)) > 1:\n",
    "            break\n",
    "\n",
    "    # Diccionario para almacenar los modelos y sus resultados de evaluación para cada cliente\n",
    "    client_models = {}\n",
    "    \n",
    "    # Modelos a entrenar\n",
    "    models = {\n",
    "        'GradientBoosting': GradientBoostingClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(),\n",
    "        'XGBoost': xgb.XGBClassifier(),\n",
    "        'LightGBM': lgb.LGBMClassifier()\n",
    "    }\n",
    "     \n",
    "    # Entrenar y evaluar modelos para cada cliente\n",
    "    for client in clients:\n",
    "        # Dividir los datos del cliente\n",
    "        X_client_train, X_client_test, y_client_train, y_client_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Diccionario para almacenar los resultados de los modelos para el cliente actual\n",
    "        client_results = {}\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "        # Entrenar el modelo\n",
    "            model.fit(X_client_train, y_client_train)\n",
    "\n",
    "            # Evaluar el modelo\n",
    "            y_pred = model.predict(X_client_test)\n",
    "            accuracy = accuracy_score(y_client_test, y_pred)\n",
    "\n",
    "            # Almacenar la precisión del modelo\n",
    "            client_results[model_name] = accuracy\n",
    "\n",
    "        # Almacenar los resultados del cliente\n",
    "        client_models[client] = client_results\n",
    "\n",
    "    return client_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 61\u001b[0m\n\u001b[0;32m     54\u001b[0m client_datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_1\u001b[39m\u001b[38;5;124m'\u001b[39m: client1_data,\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_2\u001b[39m\u001b[38;5;124m'\u001b[39m: client2_data,\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_3\u001b[39m\u001b[38;5;124m'\u001b[39m: client3_data\n\u001b[0;32m     58\u001b[0m }\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Entrenar y evaluar los modelos descentralizados\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m client_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_evaluate_decentralized_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_datasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Imprimir los resultados\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client, model_info \u001b[38;5;129;01min\u001b[39;00m client_models\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m, in \u001b[0;36mtrain_evaluate_decentralized_models\u001b[1;34m(client_datasets)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Dividir los datos hasta que y_train tenga al menos dos clases\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2876\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m-> 2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2878\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2878\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2878\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:266\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m     )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# TODO: we should probably use _is_pandas_df_or_series(X) instead but this\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# would require updating some tests such as test_train_test_split_mock_pandas.\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_polars_df_or_series(X):\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:47\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[1;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m     42\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(key)):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "def train_evaluate_decentralized_models(client_datasets):\n",
    "    # Diccionario para almacenar los modelos y sus resultados de evaluación para cada cliente\n",
    "    client_models = {}\n",
    "    \n",
    "    # Modelos a entrenar\n",
    "    models = {\n",
    "        'GradientBoosting': GradientBoostingClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(),\n",
    "        'XGBoost': xgb.XGBClassifier(),\n",
    "        'LightGBM': lgb.LGBMClassifier()\n",
    "    }\n",
    "    \n",
    "    # Entrenar y evaluar modelos para cada cliente\n",
    "    for client, data in client_datasets.items():\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        \n",
    "        # Dividir los datos hasta que y_train tenga al menos dos clases\n",
    "        while True:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            if len(np.unique(y_train)) > 1:\n",
    "                break\n",
    "        \n",
    "        # Diccionario para almacenar los resultados de los modelos para el cliente actual\n",
    "        client_results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            # Entrenar el modelo\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluar el modelo\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Almacenar la precisión del modelo\n",
    "            client_results[model_name] = accuracy\n",
    "        \n",
    "        # Almacenar los resultados del cliente\n",
    "        client_models[client] = client_results\n",
    "    \n",
    "    return client_models\n",
    "\n",
    "\n",
    "\n",
    "# Crear un diccionario con los datasets de los clientes\n",
    "client_datasets = {\n",
    "    'client_1': client1_data,\n",
    "    'client_2': client2_data,\n",
    "    'client_3': client3_data\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar los modelos descentralizados\n",
    "client_models = train_evaluate_decentralized_models(client_datasets)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for client, model_info in client_models.items():\n",
    "    print(f\"Client: {client}\")\n",
    "    for model_name, accuracy in model_info.items():\n",
    "        print(f\"  Model: {model_name}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión promedio para los modelos descentralizados\n",
    "decentralized_results = {}\n",
    "for model_name in models.keys():\n",
    "    decentralized_results[model_name] = (decentralized_results_client1[model_name] + decentralized_results_client2[model_name] + decentralized_results_client3[model_name]) / 3\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Centralized Model Accuracy:\")\n",
    "for model_name, accuracy in centralized_results.items():\n",
    "    print(f\"{model_name}: {accuracy}\")\n",
    "\n",
    "print(\"\\nDecentralized Model Accuracy (Federated Learning):\")\n",
    "for model_name, accuracy in decentralized_results.items():\n",
    "    print(f\"{model_name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión promedio para los modelos descentralizados\n",
    "decentralized_results = {}\n",
    "for model_name in models.keys():\n",
    "    decentralized_results[model_name] = (decentralized_results_client1[model_name] + decentralized_results_client2[model_name] + decentralized_results_client3[model_name]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir los resultados\n",
    "print(\"Centralized Model Accuracy:\")\n",
    "for model_name, accuracy in centralized_results.items():\n",
    "    print(f\"{model_name}: {accuracy}\")\n",
    "\n",
    "print(\"\\nDecentralized Model Accuracy (Federated Learning):\")\n",
    "for model_name, accuracy in decentralized_results.items():\n",
    "    print(f\"{model_name}: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
